{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be82e23-332f-455b-8e0e-0c017f841f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3c03c-37de-4652-8e83-d57c0823ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_matrix.resample(\"D\").sum().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec709a-2ac1-4e94-a279-064d384bad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "long=[e for e in data.columns if \"long\" in e]\n",
    "short=[e for e in data.columns if \"short\" in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f4b47-b10f-4e73-b91a-12a40c5f2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import ward, fcluster\n",
    "import random \n",
    "\n",
    "Z= data[long].loc[:\"2022-11-01\"].corr()  ################  bigdf_PTN_DD sul drawdown oppure bigdf_PTN sulle operazioni\n",
    "\n",
    "Zlista = Z.index.values.tolist()\n",
    "\n",
    "linked = linkage(Z, 'single')\n",
    "\n",
    "labelList = Zlista\n",
    "\n",
    "level = 50 ######### numero di cluster \n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "dendro=dendrogram(linked,\n",
    "            orientation='top',\n",
    "            labels=labelList,\n",
    "            distance_sort='Descending',\n",
    "            truncate_mode='lastp', \n",
    "            show_leaf_counts=True,\n",
    "            p=level)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "label = fcluster(linked, level, criterion='maxclust')\n",
    "\n",
    "df_clst = pd.DataFrame()\n",
    "df_clst[\"index\"]  = Z.index\n",
    "df_clst['label']  = label\n",
    "\n",
    "LS=[]\n",
    "for i in range(level):\n",
    "    elements = df_clst[df_clst['label']==i+1]['index'].tolist()  \n",
    "    size = len(elements)\n",
    "    print('\\n Cluster {}: N = {}'.format(i+1, size))\n",
    "    LS.append(elements)\n",
    "\n",
    "\n",
    "ok=[]\n",
    "ok2=[]\n",
    "for idn in tqdm(range(len(LS))):\n",
    "    v_max=[]\n",
    "    x=data[LS[idn]]\n",
    "    if len(x.columns)>0:\n",
    "        for k in x.columns:\n",
    "            g=data[k].loc[:\"2022-11-01\"]\n",
    "            g=g.where(g!=0).dropna()\n",
    "            \n",
    "            p=profit_factor(g)\n",
    "            k=kestner_ratio(g)\n",
    "            c=calmar_ratio(g)\n",
    "            sr=old_sharpe_ratio(g)\n",
    "            m_var=-np.var(g)\n",
    "            g=(p+k+c)#*len(g)#*g.sum()\n",
    "            av=avg_trade(g)\n",
    "\n",
    "            v_max.append(av)#(random.choice([p,k,c,sr,m_var,av])) ######## qui metti cosa vuoi valutare\n",
    "           \n",
    "        if len(v_max)>0:\n",
    "            r=v_max.index(max(v_max))\n",
    "            ok2.append(max(v_max))\n",
    "            ok.append(x.iloc[:,r].name)\n",
    "\n",
    "ls_d=data[ok]#df_matrix[ok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a0f06-8e2d-4f74-bcc8-13895897ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import ward, fcluster\n",
    "\n",
    "\n",
    "\n",
    "Z= data[short].loc[:\"2022-11-01\"].corr()  ################  bigdf_PTN_DD sul drawdown oppure bigdf_PTN sulle operazioni\n",
    "\n",
    "Zlista = Z.index.values.tolist()\n",
    "\n",
    "linked = linkage(Z, 'single')\n",
    "\n",
    "labelList = Zlista\n",
    "\n",
    "level = 50 ######### numero di cluster \n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "dendro=dendrogram(linked,\n",
    "            orientation='top',\n",
    "            labels=labelList,\n",
    "            distance_sort='Descending',\n",
    "            truncate_mode='lastp', \n",
    "            show_leaf_counts=True,\n",
    "            p=level)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "label = fcluster(linked, level, criterion='maxclust')\n",
    "\n",
    "df_clst = pd.DataFrame()\n",
    "df_clst[\"index\"]  = Z.index\n",
    "df_clst['label']  = label\n",
    "\n",
    "LS=[]\n",
    "for i in range(level):\n",
    "    elements = df_clst[df_clst['label']==i+1]['index'].tolist()  \n",
    "    size = len(elements)\n",
    "    print('\\n Cluster {}: N = {}'.format(i+1, size))\n",
    "    LS.append(elements)\n",
    "\n",
    "\n",
    "ok=[]\n",
    "ok2=[]\n",
    "for idn in tqdm(range(len(LS))):\n",
    "    v_max=[]\n",
    "    x=data[LS[idn]]\n",
    "    if len(x.columns)>0:\n",
    "        for k in x.columns:\n",
    "            g=data[k].loc[:\"2022-11-01\"]\n",
    "            g=g.where(g!=0).dropna()\n",
    "            \n",
    "            p=profit_factor(g)\n",
    "            k=kestner_ratio(g)\n",
    "            c=calmar_ratio(g)\n",
    "            sr=old_sharpe_ratio(g)\n",
    "            m_var=-np.var(g)\n",
    "            g=(p+k+c)#*len(g)#*g.sum()\n",
    "            av=avg_trade(g)\n",
    "\n",
    "            v_max.append(av)#(random.choice([p,k,c,sr,m_var,av])) ######## qui metti cosa vuoi valutare\n",
    "            #v_max.append(m_var)\n",
    "        if len(v_max)>0:\n",
    "            r=v_max.index(max(v_max))\n",
    "            ok2.append(max(v_max))\n",
    "            ok.append(x.iloc[:,r].name)\n",
    "\n",
    "ls_s=data[ok]#df_matrix[ok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76340703-5ee5-4184-b37c-3b1589a1e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest , chi2,GenericUnivariateSelect\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "DF=df_matrix.resample(\"D\").sum()\n",
    "\n",
    "dataset=carica_storico_fast(SIMBOLO,\"UTC\",0,\"60min\",\"2010-01-01\",\"2024-01-01\",0,0)\n",
    "dataset=dataset[[\"open\",\"high\",\"low\",\"close\",\"volume\"]]\n",
    "dataset = dataset.resample(\"D\").agg({'open': 'first','high': 'max','low':'min','close':'last','volume':'sum'}).dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996902f4-505d-4b5e-ac07-352739afd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l=pd.DataFrame()\n",
    "for e in tqdm(range(len(DF.columns))):\n",
    "    a=DF.iloc[:,e].to_frame()\n",
    "    #a=a.loc[\"2019-01-01\":]\n",
    "    a=a[a.index.dayofweek<5]\n",
    "    a.columns=([\"operations\"])\n",
    "    a[\"cumulato\"]=a.operations.cumsum()\n",
    "    a[\"cumulato_mean5\"]=a[\"cumulato\"].rolling(5).mean()\n",
    "    a[\"cumulato_mean30\"]=a[\"cumulato\"].rolling(30).mean()\n",
    "    a[\"cumulato_mean100\"]=a[\"cumulato\"].rolling(100).mean()\n",
    "    a[\"cumulato_log\"]=np.log(a[\"cumulato\"])         \n",
    "    a[\"cumulato_log\"][a[\"cumulato_log\"]==-np.inf]=0\n",
    "    a[\"cumulato_max\"]=a.operations.cummax()\n",
    "    a[\"cumulato_min\"]=a.operations.cummin()\n",
    "    \n",
    "    tmp_pf=a.operations[a.operations!=0].expanding().apply(profit_factor)\n",
    "    a[\"profit_factor_exp\"]=tmp_pf\n",
    "    a[\"profit_factor_exp\"]=a[\"profit_factor_exp\"].fillna(method=\"ffill\")\n",
    "    a[\"profit_factor_exp\"]=a[\"profit_factor_exp\"].fillna(0)\n",
    "    tmp_pf=a.operations[a.operations!=0].rolling(30).apply(profit_factor)\n",
    "    a[\"profit_factor_rol\"]=tmp_pf\n",
    "    a[\"profit_factor_rol\"]=a[\"profit_factor_rol\"].fillna(method=\"ffill\")\n",
    "    a[\"profit_factor_rol\"]=a[\"profit_factor_rol\"].fillna(0)\n",
    "    a[\"drawdown\"]=drawdown(a.cumulato)\n",
    "    a[\"drawdown_inv\"]=a[\"drawdown\"]*(-1)\n",
    "    \n",
    "    a[\"price_close\"]=dataset.close\n",
    "    \n",
    "    a[\"price_close_50\"]=dataset.close.rolling(50).mean()\n",
    "    a[\"price_close_30\"]=dataset.close.rolling(30).mean()\n",
    "    a[\"price_close_50_inv\"]=a[\"price_close_50\"]*(-1)\n",
    "    a[\"price_close_30_inv\"]=a[\"price_close_30\"]*(-1) \n",
    "    a[\"price_close_80\"]=dataset.close.rolling(80).mean()\n",
    "    a[\"price_close_100\"]=dataset.close.rolling(100).mean()\n",
    "    a[\"price_close_80_inv\"]=a[\"price_close_80\"]*(-1)\n",
    "    a[\"price_close_100_inv\"]=a[\"price_close_100\"]*(-1)\n",
    "    \n",
    "    a[\"price_close_inv\"]=dataset.close*(-1)\n",
    "    a[\"price_close_pct_1\"]=a.price_close.pct_change(1)\n",
    "    a[\"price_close_pct_1\"]=a[\"price_close_pct_1\"].fillna(0)\n",
    "    a[\"price_close_pct_inv_1\"]=a[\"price_close_pct_1\"]*(-1)\n",
    "    \n",
    "    #a[\"price_close_pass\"]=dataset.close.shift(1)\n",
    "    \n",
    "    a[\"price_volume\"]=dataset.volume\n",
    "    a[\"price_volume_pct\"]=a.price_volume.pct_change(1)\n",
    "    a[\"price_volume_pct\"]=a[\"price_volume_pct\"].fillna(0)\n",
    "    a[\"price_volume_pct_inv\"]=a[\"price_volume_pct\"]*(-1)\n",
    "    ########################################################\n",
    "\n",
    "    X=a.iloc[:,1:].copy()\n",
    "    X=X.fillna(0)\n",
    "    y=a.iloc[:,0].copy()\n",
    "    y[y>0]=1\n",
    "    y[y<0]=2\n",
    "    y=y.shift(-1)\n",
    "    y=y.fillna(0)\n",
    "\n",
    "    #######################################################\n",
    "\n",
    "    \n",
    "\n",
    "    #######################################################\n",
    "\n",
    "    class_weights = compute_class_weight(\n",
    "                                            class_weight = \"balanced\",\n",
    "                                            classes = np.unique(y),\n",
    "                                            y = y                                                    \n",
    "                                        )\n",
    "    class_weights = dict(zip(np.unique(y), class_weights))\n",
    "    \n",
    "    selector = SelectKBest(f_regression,k=3) #10\n",
    "    selector.fit_transform(X, y) \n",
    "    columns_idx = selector.get_support(indices=True)\n",
    "    X=X.iloc[:,columns_idx]\n",
    "    print(X.columns)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15 , random_state=42,shuffle=False)\n",
    "    #######################################################\n",
    "\n",
    "    #model = HistGradientBoostingClassifier(loss= 'auto' ,random_state=0,max_iter=10 ,class_weight=class_weights, max_depth=10) #max_iter=3 #max_depth=None\n",
    "    model = RandomForestClassifier(n_estimators=11, criterion='gini', max_depth=7, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=-1, random_state=1, verbose=0, warm_start=False, class_weight=class_weights, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    predict=model.predict(X)\n",
    "    predict=np.where(predict==2,-1,predict)\n",
    "\n",
    "    #######################################################\n",
    "    \n",
    "    \n",
    "\n",
    "    a[\"predict\"]=predict\n",
    "    ac=accuracy_score(y_train , a[\"predict\"].loc[:y_train.index[-1]])\n",
    "    print(\"Accuracy:\",round(ac,2))\n",
    "    \n",
    "    if (ac>0.6)&(ac<0.95):\n",
    "        a[\"controlled_operations\"]=a.operations*a.predict.shift(1)\n",
    "        a[[\"controlled_operations\",\"operations\"]].cumsum().plot(title=DF.iloc[:,e].name)\n",
    "        plt.axvline(x=y_test.index[0],color=\"red\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        b=a[\"controlled_operations\"].to_frame()\n",
    "        b.columns=([DF.iloc[:,e].name])\n",
    "        df_l=pd.concat([df_l,b],axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35c4f6-6b43-4bc3-a3f0-fe8ee8121a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l.sum(axis=1).loc[y_test.index[0]:].cumsum().plot(figsize=(10,10),label=\"EQC\")\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49962d5-1e00-4a09-84ac-119a768591dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l.sum(axis=1).loc[y_test.index[0]:].cumsum().plot(figsize=(10,10),label=\"EQC\")\n",
    "plt.legend(loc='upper left')\n",
    "DF.sum(axis=1).loc[y_test.index[0]:].cumsum().plot(secondary_y=True,label=\"ORIGINALE\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
