{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import mplfinance as mpf\n",
    "from datetime import timedelta\n",
    "\n",
    "def performance_report_gen(tradelist):\n",
    "    res=pd.DataFrame()\n",
    "    d = {\"Profit\": sum(tradelist),\n",
    "         \"MaxDD\" : max_draw_down(tradelist),\n",
    "         \"Operations\":operation_number(tradelist),\n",
    "         \"AverageTrade\": avg_trade(tradelist),\n",
    "         \"ProfitFactor\": profit_factor(tradelist),\n",
    "         \"PctWin\": percent_win(tradelist),\n",
    "         \"Kestner_Ratio\": kestner_ratio_daily(tradelist)}\n",
    "    res=pd.DataFrame(data=d,index=[0])\n",
    "    return res\n",
    "\n",
    "def kestner_ratio_daily(operations):\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt \n",
    "    from scipy import stats\n",
    "    \n",
    "    if len(operations)>3:\n",
    "        daily_operations = operations\n",
    "        daily_equity = daily_operations.cumsum()\n",
    "        index = np.array(np.arange(1,daily_operations.count() + 1))\n",
    "\n",
    "        x = index\n",
    "        y = daily_equity\n",
    "        gradient, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "        if std_err != 0 and len(index) > 0:\n",
    "            return round(gradient / (std_err * len(index)),2)\n",
    "        else:\n",
    "            return np.inf\n",
    "    else:\n",
    "        return np.inf\n",
    "    \n",
    "def performance_report_fast(tradelist,\n",
    "                       initial_capital,\n",
    "                       risk_free_rate,\n",
    "                       interactive):\n",
    "    print(\"*************************************************************************\")\n",
    "    print(\"*** Performance Report Fast - Copyright 2020 - by Gandalf Project R&D ***\")\n",
    "    print(\"*************************************************************************\")\n",
    "    if tradelist.empty:\n",
    "        print(\"\")\n",
    "        print(\"Nessuna operazione registrata!\")\n",
    "        return\n",
    "    else: \n",
    "        print(\"\")\n",
    "        print(\"Compound Annual Growth Rate CAGR: \" + str(cagr(tradelist.operations,initial_capital)) + \" (capital = \" + str(initial_capital) + \")\")\n",
    "        print(\"Annual Return: \" + str(annual_return(tradelist.operations,initial_capital)) + \" (capital = \" + str(initial_capital) + \")\")\n",
    "        print(\"\")\n",
    "        print(\"Calmar Ratio (yearly):\", calmar_ratio(tradelist.operations))\n",
    "        print(\"Sharpe Ratio: \" + str(sharpe_ratio(tradelist.operations, initial_capital, risk_free_rate)) + \" (capital = \" + str(initial_capital) + \", risk free rate = \" + str(risk_free_rate) + \")\")\n",
    "        print(\"Sortino Ratio: \" + str(sortino_ratio(tradelist.operations, initial_capital, risk_free_rate / 12)) + \" (capital = \" + str(initial_capital) + \", risk free rate = \" + str(risk_free_rate / 12) + \")\")\n",
    "        print(\"Omega Ratio: \" + str(omega_ratio(tradelist.operations,100)) + \" (threshold = 100)\") \n",
    "        print(\"Kestner Ratio:\", kestner_ratio(tradelist.operations))\n",
    "        print(\"\")\n",
    "        print(\"Profit:                  \", int(tradelist.operations.sum()))\n",
    "        print(\"Operations:              \", operation_number(tradelist.operations))\n",
    "        print(\"Average Trade:           \", avg_trade(tradelist.operations))\n",
    "        print(\"\")\n",
    "        print(\"Profit Factor:           \", profit_factor(tradelist.operations))\n",
    "        print(\"Gross Profit:            \", gross_profit(tradelist.operations))\n",
    "        print(\"Gross Loss:              \", gross_loss(tradelist.operations))\n",
    "        print(\"\")\n",
    "        print(\"Percent Winning Trades:  \", percent_win(tradelist.operations))\n",
    "        print(\"Percent Losing Trades:   \", round(100 - percent_win(tradelist.operations),2))\n",
    "        print(\"Reward Risk Ratio:       \", reward_risk_ratio(tradelist.operations))\n",
    "        print(\"\")\n",
    "        print(\"Max Gain:                \", max_gain(tradelist.operations), \" in date \", max_gain_date(tradelist.operations))\n",
    "        print(\"Average Gain:            \", avg_gain(tradelist.operations))\n",
    "        print(\"Max Loss:                \", max_loss(tradelist.operations), \" in date \", max_loss_date(tradelist.operations))\n",
    "        print(\"Average Loss:            \", avg_loss(tradelist.operations))\n",
    "        print(\"\")\n",
    "        print(\"Avg Delay Between Peaks: \", avg_delay_between_peaks(tradelist.operations.cumsum()))\n",
    "        print(\"Max Delay Between Peaks: \", max_delay_between_peaks(tradelist.operations.cumsum()))\n",
    "        print(\"\")\n",
    "        print(\"Trades Standard Deviation: \", tradelist.operations.std())\n",
    "        print(\"Equity Standard Deviation: \", tradelist.operations.cumsum().std())\n",
    "        print(\"\")\n",
    "        print(\"Avg Open Draw Down:      \", avgdrawdown_nozero(tradelist.operations.cumsum()))\n",
    "        print(\"Max Open Draw Down:      \", max_draw_down(tradelist.operations.cumsum()))\n",
    "        print(\"\")\n",
    "        print(\"Avg Closed Draw Down:    \", avgdrawdown_nozero(tradelist.operations.cumsum()))\n",
    "        print(\"Max Closed Draw Down:    \", max_draw_down(tradelist.operations.cumsum()))\n",
    "        print(\"\")\n",
    "        print(\"Draw Down Statistics: \", drawdown_statistics(tradelist.operations.cumsum()))\n",
    "        print(\"\")\n",
    "        \n",
    "        print(\"Operations Statistics:\\n\")\n",
    "\n",
    "        if interactive == False:\n",
    "            plot_equity(tradelist.operations.cumsum(),\"green\")\n",
    "            plot_equity_price(dataset, tradelist.operations.cumsum())\n",
    "            plot_drawdown(tradelist.operations.cumsum(),\"red\")\n",
    "            plot_annual_histogram(tradelist.operations)\n",
    "            plot_monthly_bias_histogram(tradelist.operations)\n",
    "            plot_equity_heatmap(tradelist.operations,False)\n",
    "\n",
    "        else:\n",
    "            plot_equity_interactive(tradelist.operations.cumsum(),\"green\")\n",
    "            plot_drawdown_interactive(tradelist.operations.cumsum())\n",
    "            plot_annual_histogram_interactive(tradelist.operations)\n",
    "            plot_monthly_bias_histogram_interactive(tradelist.operations)\n",
    "            plot_equity_heatmap_interactive(tradelist.operations,False)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c407357-f008-4a85-8472-d8f1694b2a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c55e302-3505-4e1d-ba94-31272eb69d4f",
   "metadata": {},
   "source": [
    "@jit(nopython=True)\n",
    "def engine(pct,pct_total,ptn_body,ptn_range,\n",
    "           np_open, np_high, np_low, np_close, direzione,lookback,n_days):\n",
    "    \n",
    "    gain_loss=[]\n",
    "    ls_date=[]\n",
    "    conta=0\n",
    "    for i in (range(len(np_open)-n_days)):\n",
    "        if i >lookback:\n",
    "            op=np_open[i-lookback:i]\n",
    "            hi=np_high[i-lookback:i]\n",
    "            lo=np_low[i-lookback:i]\n",
    "            cl=np_close[i-lookback:i]\n",
    "\n",
    "            a=cl-op\n",
    "            body=(a - np.min(a))/np.ptp(a)  ###  2.*(a - np.min(a))/np.ptp(a)-1 ### per 1 / -1\n",
    "            \n",
    "            a=hi-lo\n",
    "            range_=(a - np.min(a))/np.ptp(a)\n",
    "     \n",
    "            diff_1=body-ptn_body\n",
    "            diff_2=range_-ptn_range\n",
    "            diff_1=np.where((diff_1<pct)&(diff_1>-pct),1,diff_1)\n",
    "            diff_1=np.where(diff_1!=1,0,diff_1)\n",
    "            diff_2=np.where((diff_2<pct)&(diff_2>-pct),1,diff_2)\n",
    "            diff_2=np.where(diff_2!=1,0,diff_2)\n",
    "            if (my_sum(diff_1)>=pct_total)&(my_sum(diff_2)>=pct_total)&(direzione==\"UP\"):\n",
    "                tmp_ls=[]\n",
    "                #for n in range(1,n_days+1):\n",
    "                gl_1=np_open[i+n_days+1] - np_open[i+1]\n",
    "                tmp_ls.append(gl_1)\n",
    "                gain_loss.append(tmp_ls)\n",
    "                ls_date.append(i)\n",
    "            if (my_sum(diff_1)>=pct_total)&(my_sum(diff_2)>=pct_total)&(direzione==\"DOWN\"):\n",
    "                tmp_ls=[]\n",
    "                #for n in range(1,n_days+1):\n",
    "                gl_1=np_open[i+1] - np_open[i+n_days+1] \n",
    "                tmp_ls.append(gl_1)\n",
    "                gain_loss.append(tmp_ls)\n",
    "                ls_date.append(i)\n",
    "    return gain_loss , ls_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def my_sum(d):\n",
    "    total = 0.0\n",
    "    for valore in d:\n",
    "        total += valore\n",
    "    return total\n",
    "\n",
    "\n",
    "from numba import jit\n",
    "@jit(nopython=True)\n",
    "def engine(pct,pct_total,ptn_body,ptn_range,\n",
    "           np_open, np_high, np_low, np_close, direzione,lookback,n_days):\n",
    "    \n",
    "    gain_loss=[]\n",
    "    ls_date=[]\n",
    "    conta=0\n",
    "    mp=np.zeros(len(np_open))\n",
    "    for i in (range(len(np_open)-n_days)):\n",
    "        if i >lookback:\n",
    "            op=np_open[i-lookback:i]\n",
    "            hi=np_high[i-lookback:i]\n",
    "            lo=np_low[i-lookback:i]\n",
    "            cl=np_close[i-lookback:i]\n",
    "\n",
    "            a=cl-op\n",
    "            body=(a - np.min(a))/np.ptp(a)  ###  2.*(a - np.min(a))/np.ptp(a)-1 ### per 1 / -1\n",
    "            \n",
    "            a=hi-lo\n",
    "            range_=(a - np.min(a))/np.ptp(a)\n",
    "     \n",
    "            diff_1=body-ptn_body\n",
    "            diff_2=range_-ptn_range\n",
    "            diff_1=np.where((diff_1<pct)&(diff_1>-pct),1,diff_1)\n",
    "            diff_1=np.where(diff_1!=1,0,diff_1)\n",
    "            diff_2=np.where((diff_2<pct)&(diff_2>-pct),1,diff_2)\n",
    "            diff_2=np.where(diff_2!=1,0,diff_2)\n",
    "            if (my_sum(diff_1)>=pct_total)&(my_sum(diff_2)>=pct_total)&(direzione==\"UP\"):\n",
    "                tmp_ls=[]\n",
    "                for n in range(1,n_days+1):\n",
    "                    gl_1=np_open[i+n+1] - np_open[i+1]\n",
    "                    tmp_ls.append(gl_1)\n",
    "                gain_loss.append(tmp_ls)\n",
    "                ls_date.append(i)\n",
    "            if (my_sum(diff_1)>=pct_total)&(my_sum(diff_2)>=pct_total)&(direzione==\"DOWN\"):\n",
    "                tmp_ls=[]\n",
    "                for n in range(1,n_days+1):\n",
    "                    gl_1=np_open[i+1] - np_open[i+n+1] \n",
    "                    tmp_ls.append(gl_1)\n",
    "                gain_loss.append(tmp_ls)\n",
    "                ls_date.append(i)\n",
    "    return gain_loss , ls_date\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def search_pattern(np_open,np_high,np_low,np_close,n_days,lookback,fraction_movement):\n",
    "    \n",
    "    down_ls=[]\n",
    "    up_ls=[]\n",
    "    position_down=[]\n",
    "    position_up=[]\n",
    "    for i in (range(len(np_open))):\n",
    "        op=np_open[i-lookback:i]\n",
    "        hi=np_high[i-lookback:i]\n",
    "        lo=np_low[i-lookback:i]\n",
    "        cl=np_close[i-lookback:i]\n",
    "\n",
    "        try :\n",
    "            for n in range(1,n_days+1): \n",
    "                if  np_open[i+1] - np_open[i+n+1] >= fraction_movement*np_open[i+1]:\n",
    "                    if i >=lookback :\n",
    "                        a=cl-op\n",
    "                        body=(a - np.min(a))/np.ptp(a)\n",
    "                        a=hi-lo\n",
    "                        range_=(a - np.min(a))/np.ptp(a)\n",
    "                        down_ls.append([body,range_])\n",
    "                    #print('Down',i,n)\n",
    "                    position_down.append([i,n])\n",
    "                    break\n",
    "                elif np_open[i+n+1] - np_open[i+1] >= fraction_movement*np_open[i+1] :\n",
    "                    if i >lookback :                    \n",
    "                        a=cl-op\n",
    "                        body=(a - np.min(a))/np.ptp(a)\n",
    "                        a=hi-lo\n",
    "                        range_=(a - np.min(a))/np.ptp(a)\n",
    "                        up_ls.append([body,range_])\n",
    "                    #print('Up',i,n)\n",
    "                    position_up.append([i,n])\n",
    "                    break\n",
    "        except :\n",
    "            print(i)\n",
    "            pass\n",
    "    return up_ls , down_ls , position_up , position_down\n",
    "\n",
    "   \n",
    "def generate_signal(dataset,lookback,pct_accettata,fraction_movement,n_patterny,direzione):\n",
    "    \n",
    "    if direzione == \"long\":\n",
    "\n",
    "        pct=round(1-float((1/100)*pct_accettata),1)\n",
    "        pct_total=int((lookback/100)*pct_accettata)\n",
    "\n",
    "        ptn_body=up_ls[n_patterny][0]\n",
    "        ptn_range=up_ls[n_patterny][1]\n",
    "\n",
    "        data=dataset.copy()\n",
    "        data[\"signal\"]=0\n",
    "\n",
    "        for e in tqdm(range(len(data)-lookback)):\n",
    "\n",
    "            a=data.close[e:e+lookback].values-data.open[e:e+lookback].values\n",
    "            body=(a - np.min(a))/np.ptp(a)  \n",
    "\n",
    "            a=data.high[e:e+lookback].values-data.low[e:e+lookback].values\n",
    "            range_=(a - np.min(a))/np.ptp(a)\n",
    "\n",
    "            diff_1=body-ptn_body\n",
    "            diff_2=range_-ptn_range\n",
    "            diff_1=np.where((diff_1<pct)&(diff_1>-pct),1,diff_1)\n",
    "            diff_1=np.where(diff_1!=1,0,diff_1)\n",
    "            diff_2=np.where((diff_2<pct)&(diff_2>-pct),1,diff_2)\n",
    "            diff_2=np.where(diff_2!=1,0,diff_2)\n",
    "            if (sum(diff_1)>=pct_total)&(sum(diff_2)>=pct_total):\n",
    "                data[\"signal\"][e+lookback]=1\n",
    "\n",
    "        return data[\"signal\"]\n",
    "\n",
    "\n",
    "    if direzione == \"short\":\n",
    "\n",
    "        pct=round(1-float((1/100)*pct_accettata),1)\n",
    "        pct_total=int((lookback/100)*pct_accettata)\n",
    "\n",
    "        ptn_body=down_ls[n_patterny][0]\n",
    "        ptn_range=down_ls[n_patterny][1]\n",
    "\n",
    "        data=dataset.copy()\n",
    "        data[\"signal\"]=0\n",
    "\n",
    "        for e in tqdm(range(len(data)-lookback)):\n",
    "\n",
    "            a=data.close[e:e+lookback].values-data.open[e:e+lookback].values\n",
    "            body=(a - np.min(a))/np.ptp(a)  \n",
    "\n",
    "            a=data.high[e:e+lookback].values-data.low[e:e+lookback].values\n",
    "            range_=(a - np.min(a))/np.ptp(a)\n",
    "\n",
    "            diff_1=body-ptn_body\n",
    "            diff_2=range_-ptn_range\n",
    "            diff_1=np.where((diff_1<pct)&(diff_1>-pct),1,diff_1)\n",
    "            diff_1=np.where(diff_1!=1,0,diff_1)\n",
    "            diff_2=np.where((diff_2<pct)&(diff_2>-pct),1,diff_2)\n",
    "            diff_2=np.where(diff_2!=1,0,diff_2)\n",
    "            if (sum(diff_1)>=pct_total)&(sum(diff_2)>=pct_total):\n",
    "                data[\"signal\"][e+lookback]=1\n",
    "\n",
    "        return data[\"signal\"]\n",
    "    \n",
    "def generate_signal2(dataset,lookback,pct_accettata,fraction_movement,n_patterny,direzione):\n",
    "    \n",
    "    if direzione == \"long\":\n",
    "\n",
    "        pct=round(1-float((1/100)*pct_accettata),1)\n",
    "        pct_total=int((lookback/100)*pct_accettata)\n",
    "\n",
    "        ptn_body=up_ls[n_patterny][0]\n",
    "        ptn_range=up_ls[n_patterny][1]\n",
    "\n",
    "        data=dataset.copy()\n",
    "        data[\"signal\"]=0\n",
    "        \n",
    "        \n",
    "        dclose=data.close.values\n",
    "        dopen=data.open.values\n",
    "        dhigh=data.high.values\n",
    "        dlow=data.low.values\n",
    "\n",
    "        for e in (range(len(data)-lookback)):\n",
    "\n",
    "            a=dclose[e:e+lookback]-dopen[e:e+lookback]\n",
    "            body=(a - np.min(a))/np.ptp(a)  \n",
    "\n",
    "            a=dhigh[e:e+lookback]-dlow[e:e+lookback]\n",
    "            range_=(a - np.min(a))/np.ptp(a)\n",
    "\n",
    "            diff_1=body-ptn_body\n",
    "            diff_2=range_-ptn_range\n",
    "            diff_1=np.where((diff_1<pct)&(diff_1>-pct),1,diff_1)\n",
    "            diff_1=np.where(diff_1!=1,0,diff_1)\n",
    "            diff_2=np.where((diff_2<pct)&(diff_2>-pct),1,diff_2)\n",
    "            diff_2=np.where(diff_2!=1,0,diff_2)\n",
    "            if (sum(diff_1)>=pct_total)&(sum(diff_2)>=pct_total):\n",
    "                data[\"signal\"][e+lookback]=1\n",
    "\n",
    "        return data[\"signal\"]\n",
    "\n",
    "\n",
    "    if direzione == \"short\":\n",
    "\n",
    "        pct=round(1-float((1/100)*pct_accettata),1)\n",
    "        pct_total=int((lookback/100)*pct_accettata)\n",
    "\n",
    "        ptn_body=down_ls[n_patterny][0]\n",
    "        ptn_range=down_ls[n_patterny][1]\n",
    "\n",
    "        data=dataset.copy()\n",
    "        data[\"signal\"]=0\n",
    "        \n",
    "        dclose=data.close.values\n",
    "        dopen=data.open.values\n",
    "        dhigh=data.high.values\n",
    "        dlow=data.low.values\n",
    "\n",
    "        for e in (range(len(data)-lookback)):\n",
    "\n",
    "            a=dclose[e:e+lookback]-dopen[e:e+lookback]\n",
    "            body=(a - np.min(a))/np.ptp(a)  \n",
    "\n",
    "            a=dhigh[e:e+lookback]-dlow[e:e+lookback]\n",
    "            range_=(a - np.min(a))/np.ptp(a)\n",
    "\n",
    "            diff_1=body-ptn_body\n",
    "            diff_2=range_-ptn_range\n",
    "            diff_1=np.where((diff_1<pct)&(diff_1>-pct),1,diff_1)\n",
    "            diff_1=np.where(diff_1!=1,0,diff_1)\n",
    "            diff_2=np.where((diff_2<pct)&(diff_2>-pct),1,diff_2)\n",
    "            diff_2=np.where(diff_2!=1,0,diff_2)\n",
    "            if (sum(diff_1)>=pct_total)&(sum(diff_2)>=pct_total):\n",
    "                data[\"signal\"][e+lookback]=1\n",
    "\n",
    "        return data[\"signal\"]    \n",
    "\n",
    "def plot_pattern(n_pattern,exit_after_bar,direction):\n",
    "\n",
    "    if direction== \"long\":\n",
    "        name=\"Ext_\"+str(exit_after_bar)+\"_bar\"\n",
    "\n",
    "        split_day=int(name.split(\"_\")[1])\n",
    "        stampa_LONG=big_res_long[n_pattern][name]\n",
    "        idx=dataset.loc[dataset['idx'].isin(big_data_long[n_pattern])].index\n",
    "        stampa_LONG.index=idx\n",
    "        stampa_LONG.index=pd.to_datetime(stampa_LONG.index)\n",
    "        stampa_LONG.index=stampa_LONG.index + timedelta(days=split_day)\n",
    "        stampa_LONG.cumsum().plot(figsize=(20,10),title=\"Equity Pattern N:\"+str(n_pattern)+\" Exit After \"+str(n_days)+\" Bar\")\n",
    "        plt.show()\n",
    "\n",
    "        v1=position_up[n_pattern][0]\n",
    "        v2=position_up[n_pattern][1]\n",
    "        df=dataset.iloc[v1-lookback:v1] \n",
    "\n",
    "        mpf.plot(df, type='candle', style='yahoo', volume=False, title='Pattern_N:'+str(n_pattern)+\" \"+direction ,axisoff=True)\n",
    "        \n",
    "        \n",
    "    if direction== \"short\":\n",
    "        name=\"Ext_\"+str(exit_after_bar)+\"_bar\"\n",
    "\n",
    "        split_day=int(name.split(\"_\")[1])\n",
    "        stampa_SHORT=big_res_short[n_pattern][name]\n",
    "\n",
    "        idx=dataset.loc[dataset['idx'].isin(big_data_short[n_pattern])].index\n",
    "        stampa_SHORT.index=idx\n",
    "        stampa_SHORT.index=pd.to_datetime(stampa_SHORT.index)\n",
    "        stampa_SHORT.index=stampa_SHORT.index + timedelta(days=split_day)\n",
    "        stampa_SHORT.cumsum().plot(figsize=(20,10),title=\"Equity Pattern N:\"+str(n_pattern)+\" Exit After \"+str(n_days)+\" Bar\")\n",
    "\n",
    "        v1=position_down[n_pattern][0]\n",
    "        v2=position_down[n_pattern][1]\n",
    "        df=dataset.iloc[v1-lookback:v1] \n",
    "\n",
    "        mpf.plot(df, type='candle', style='yahoo', volume=False, title='Pattern_N:'+str(n_pattern)+\" \"+direction , axisoff=True)\n",
    "        \n",
    "def backtest(pct_accepted,bigpointvalue):\n",
    "\n",
    "    pct=round(1-float((1/100)*pct_accepted),1)\n",
    "    pct_total=int((lookback/100)*pct_accepted)\n",
    "\n",
    "    big_res_long=[]\n",
    "    big_data_long=[]\n",
    "    big_res_short=[]\n",
    "    big_data_short=[]\n",
    "    \n",
    "    print(\"BackTest Patterns Long\")\n",
    "    for ptn_num in tqdm(range(len(up_ls))):\n",
    "        ptn_body=up_ls[ptn_num][0]\n",
    "        ptn_range=up_ls[ptn_num][1]\n",
    "\n",
    "        j=engine(pct,pct_total,ptn_body,ptn_range,np_open, np_high, np_low, np_close,\"UP\",lookback,n_days)\n",
    "        res=pd.DataFrame(j[0])\n",
    "        names_columns=[]\n",
    "        for el in range(1,len(res.columns)+1):\n",
    "            x=\"Ext_\"+str(el)+\"_bar\"\n",
    "            names_columns.append(x)\n",
    "        res.columns=names_columns\n",
    "        res=res*bigpointvalue\n",
    "        big_res_long.append(res)\n",
    "        big_data_long.append(j[1])\n",
    "        \n",
    "    print(\"BackTest Patterns Short\")\n",
    "    for ptn_num in tqdm(range(len(down_ls))):\n",
    "        ptn_body=down_ls[ptn_num][0]\n",
    "        ptn_range=down_ls[ptn_num][1]\n",
    "\n",
    "        j=engine(pct,pct_total,ptn_body,ptn_range,np_open, np_high, np_low, np_close,\"DOWN\",lookback,n_days)\n",
    "        res=pd.DataFrame(j[0])\n",
    "        names_columns=[]\n",
    "        for el in range(1,len(res.columns)+1):\n",
    "            x=\"Ext_\"+str(el)+\"_bar\"\n",
    "            names_columns.append(x)\n",
    "        res.columns=names_columns\n",
    "        res=res*bigpointvalue\n",
    "        big_res_short.append(res)\n",
    "        big_data_short.append(j[1])\n",
    "        \n",
    "        \n",
    "    return big_res_long , big_data_long , big_res_short , big_data_short\n",
    "\n",
    "def Results_Patterns(big_res_long_short,ranking,direction):\n",
    "    \n",
    "    if direction == \"long\":\n",
    "        print(\"Risultati Patterns Long\")\n",
    "\n",
    "        df_res_long=pd.DataFrame()\n",
    "        for e in tqdm(range(len(big_res_long))):\n",
    "            x=big_res_long[e]\n",
    "            for k in range(len(x.columns)):\n",
    "                y=x.iloc[:,k].fillna(0)\n",
    "                y=y[y!=0]\n",
    "                v=performance_report_gen(y.iloc[:-1])\n",
    "                v[\"Exit\"]=x.iloc[:,k].name\n",
    "                v[\"Ptn_N°\"]=e\n",
    "                df_res_long=pd.concat([df_res_long,v])\n",
    "\n",
    "        df_res_long=df_res_long.sort_values(by=ranking,ascending=False)\n",
    "        return df_res_long\n",
    "\n",
    "    if direction == \"short\":\n",
    "        print(\"Risultati Patterns Short\")\n",
    "    \n",
    "        df_res_short=pd.DataFrame()\n",
    "        for e in tqdm(range(len(big_res_short))):\n",
    "            x=big_res_short[e]\n",
    "            for k in range(len(x.columns)):\n",
    "                y=x.iloc[:,k].fillna(0)\n",
    "                y=y[y!=0]\n",
    "                v=performance_report_gen(y.iloc[:-1])\n",
    "                v[\"Exit\"]=x.iloc[:,k].name\n",
    "                v[\"Ptn_N°\"]=e\n",
    "                df_res_short=pd.concat([df_res_short,v])\n",
    "        df_res_short=df_res_short.sort_values(by=ranking,ascending=False)\n",
    "        return df_res_short\n",
    "    \n",
    "def pandas_df_to_numpy_array(dataset):\n",
    "    dataset[\"idx\"]=list(range(len(dataset)))\n",
    "    np_open = dataset.open.values\n",
    "    np_high = dataset.high.values\n",
    "    np_low = dataset.low.values\n",
    "    np_close = dataset.close.values\n",
    "    \n",
    "    return np_open,np_high,np_low,np_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b16c59-3b39-4115-9ed5-47a4aa8fee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_frame(tf):\n",
    "    tf=tf.lower()\n",
    "    ls_tf=[\"1min\",\"5min\",\"15min\",\"30min\",\"60min\"]\n",
    "    test_ok=0\n",
    "    for e in ls_tf:\n",
    "        if e == tf:\n",
    "            tf_ok=e\n",
    "            test_ok=1\n",
    "            break\n",
    "    if test_ok == 0:\n",
    "            print(\"ERRORE - Solo time frame a: \",ls_tf,\" in ingresso\")\n",
    "    else:\n",
    "        tf_ok=tf_ok.split(\"min\")[0]\n",
    "        return int(tf_ok)\n",
    "    \n",
    "def resample_standard_session(original_tf,resample_tf,dataset):\n",
    "    \n",
    "    original_tf=test_time_frame(original_tf)\n",
    "    resample_tf=test_time_frame(resample_tf)\n",
    "    df_0=dataset.copy()\n",
    "    \n",
    "    df_0.index=df_0.index - pd.DateOffset(minutes=original_tf)\n",
    "    df_resample=df_0.resample(str(resample_tf)+'Min').agg({'open' : 'first', 'high' : 'max', 'low' : 'min', 'close' : 'last','volume':'sum'})\n",
    "    df_resample.index=df_resample.index + pd.DateOffset(minutes=resample_tf)\n",
    "    df_resample=df_resample.dropna()\n",
    "    return df_resample\n",
    "\n",
    "def load_data_intraday_fast(filename):\n",
    "    data=pd.read_csv(filename,engine=\"pyarrow\")\n",
    "    data.set_index([\"date_time\"],inplace=True)\n",
    "    data.index=pd.to_datetime(data.index)\n",
    "    return data\n",
    "\n",
    "def resample_custom_session(original_tf,resample_tf,dataset,start_time,end_time):\n",
    "    \n",
    "    original_tf=test_time_frame(original_tf)\n",
    "    resample_tf=test_time_frame(resample_tf)\n",
    "    df_0=dataset.copy()\n",
    "    \n",
    "    df_0.index=df_0.index - pd.DateOffset(minutes=original_tf)\n",
    "    \n",
    "    test_start_time=0\n",
    "    if len(start_time) == 4:\n",
    "        st_h=start_time[:2]\n",
    "        st_m=start_time[2:]\n",
    "        test_start_time=1\n",
    "        \n",
    "    test_end_time=0\n",
    "    if len(end_time) == 4:\n",
    "        en_h=end_time[:2]\n",
    "        en_m=end_time[2:]\n",
    "        test_end_time=1\n",
    "\n",
    "    if (test_start_time==0)|(test_end_time==0):\n",
    "        print(\"ERRORE - controlla gli orari di start & end\")\n",
    "    else:\n",
    "\n",
    "        dati=df_0.loc[(df_0.index.time>=datetime.time(int(st_h), int(st_m)))&(df_0.index.time<=datetime.time(int(en_h), int(en_m)))]\n",
    "        dati= dati.resample(str(resample_tf)+'Min',origin=st_h+\":\"+st_m+':00').agg({'open': 'first','high': 'max','low':'min','close':'last','volume':'sum'}).dropna()\n",
    "        dati.index=dati.index + pd.DateOffset(minutes=resample_tf)\n",
    "        \n",
    "        test_h=sorted(list(set(dati.index.time)))\n",
    "        \n",
    "        time1 = datetime.time(int(en_h),int(en_m))\n",
    "        timedelta = datetime.timedelta(minutes=original_tf)\n",
    "        tmp_datetime = datetime.datetime.combine(datetime.date(1, 1, 1), time1)\n",
    "        time2 = (tmp_datetime - timedelta).time()\n",
    "        \n",
    "        dati1=df_0.loc[(df_0.index.time>=test_h[-2])&(df_0.index.time<=time2)]\n",
    "        dati1= dati1.resample(\"D\").agg({'open': 'first','high': 'max','low':'min','close':'last','volume':'sum'}).dropna()\n",
    "        dati1.index=dati1.index + pd.DateOffset(hours=int(en_h),minutes=int(en_m))\n",
    "\n",
    "        custom_df=dati.loc[dati.index.time!=test_h[-1]].dropna()\n",
    "        custom_df=pd.concat([custom_df,dati1])\n",
    "        custom_df=custom_df.sort_index(ascending=True)\n",
    "        return custom_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc69b6-35ae-47d0-9364-97c71a724951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def carica_storico(file_name,uct_offset,type_session,resample_tf,IS,OOS,custom_session_start,custom_session_stop,noise,pct_noise):\n",
    "    import os\n",
    "    import talib as ta\n",
    "    \n",
    "    os.chdir(dir_history)\n",
    "    data = load_data_intraday_fast(file_name)  \n",
    "    print(\"Caricato storico\")\n",
    "    data = data.sort_index(ascending=True)\n",
    "    data.index = data.index.tz_localize('Etc/Zulu')\n",
    "    data.index = data.index.tz_convert(uct_offset )\n",
    "    data.index = data.index.tz_localize(None)\n",
    "    data = data[data!=0]\n",
    "    data = data.iloc[1:-1]\n",
    "    print(\"Resample dei dati\")\n",
    "    if type_session == 1:\n",
    "        dataset=resample_custom_session(\"5min\",resample_tf ,data,custom_session_start,custom_session_stop) \n",
    "    if type_session == 0:    \n",
    "        dataset=resample_standard_session(\"5min\",resample_tf,data)\n",
    "        \n",
    "    if noise == 1:\n",
    "        print(\"AGGIUNGO RUMORE\")\n",
    "        dataset=add_noise(dataset.open, dataset.high, dataset.low, dataset.close,dataset.volume, pct_noise)\n",
    "\n",
    "    history=dataset.copy()\n",
    "       \n",
    "    return history \n",
    "\n",
    "def check_history_name(file_name,dir_history):\n",
    "    import os\n",
    "    storici = os.listdir(dir_history)\n",
    "    for e in storici:\n",
    "        x=e.split(\"_\")[0]\n",
    "        x=x.replace(\"@\",\"\")\n",
    "        if x == file_name:\n",
    "            file_name=e\n",
    "            break\n",
    "    return file_name\n",
    "\n",
    "def performance_report_gen(tradelist):\n",
    "    res=pd.DataFrame()\n",
    "    d = {\"Profit\": sum(tradelist),\n",
    "         \"MaxDD\" : max_draw_down(tradelist),\n",
    "         \"Operations\":operation_number(tradelist),\n",
    "         \"AverageTrade\": avg_trade(tradelist),\n",
    "         \"ProfitFactor\": profit_factor(tradelist),\n",
    "         \"PctWin\": percent_win(tradelist),\n",
    "         \"Sharpe\": old_sharpe_ratio(tradelist.values),\n",
    "         \"Kestner_Ratio\": kestner_ratio_daily(tradelist)}\n",
    "    res=pd.DataFrame(data=d,index=[0])\n",
    "    return res\n",
    "\n",
    "\n",
    "def kestner_ratio_daily(operations):\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt \n",
    "    from scipy import stats\n",
    "    \n",
    "    if len(operations)>3:\n",
    "        daily_operations = operations\n",
    "        daily_equity = daily_operations.cumsum()\n",
    "        index = np.array(np.arange(1,daily_operations.count() + 1))\n",
    "\n",
    "        x = index\n",
    "        y = daily_equity\n",
    "        gradient, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "        if std_err != 0 and len(index) > 0:\n",
    "            return round(gradient / (std_err * len(index)),2)\n",
    "        else:\n",
    "            return np.inf\n",
    "    else:\n",
    "        return np.inf\n",
    "    \n",
    "def generate_signal_live(dataset,lookback,pct_accettata,fraction_movement,n_patterny,direzione):\n",
    "    \n",
    "    if direzione == \"long\":\n",
    "\n",
    "        pct=round(1-float((1/100)*pct_accettata),1)\n",
    "        pct_total=int((lookback/100)*pct_accettata)\n",
    "\n",
    "        ptn_body=n_patterny[0]\n",
    "        ptn_range=n_patterny[1]\n",
    "\n",
    "        data=dataset.copy()\n",
    "        data[\"signal\"]=False\n",
    "        \n",
    "        \n",
    "        dclose=data.close.values\n",
    "        dopen=data.open.values\n",
    "        dhigh=data.high.values\n",
    "        dlow=data.low.values\n",
    "\n",
    "        for e in (range(len(data)-lookback)):\n",
    "\n",
    "            a=dclose[e:e+lookback]-dopen[e:e+lookback]\n",
    "            body=(a - np.min(a))/np.ptp(a)  \n",
    "\n",
    "            a=dhigh[e:e+lookback]-dlow[e:e+lookback]\n",
    "            range_=(a - np.min(a))/np.ptp(a)\n",
    "\n",
    "            diff_1=body-ptn_body\n",
    "            diff_2=range_-ptn_range\n",
    "            diff_1=np.where((diff_1<pct)&(diff_1>-pct),1,diff_1)\n",
    "            diff_1=np.where(diff_1!=1,0,diff_1)\n",
    "            diff_2=np.where((diff_2<pct)&(diff_2>-pct),1,diff_2)\n",
    "            diff_2=np.where(diff_2!=1,0,diff_2)\n",
    "            if (sum(diff_1)>=pct_total)&(sum(diff_2)>=pct_total):\n",
    "                data[\"signal\"][e+lookback]=True\n",
    "\n",
    "        return data[\"signal\"]\n",
    "\n",
    "\n",
    "    if direzione == \"short\":\n",
    "\n",
    "        pct=round(1-float((1/100)*pct_accettata),1)\n",
    "        pct_total=int((lookback/100)*pct_accettata)\n",
    "\n",
    "        ptn_body=n_patterny[0]\n",
    "        ptn_range=n_patterny[1]\n",
    "\n",
    "        data=dataset.copy()\n",
    "        data[\"signal\"]=False\n",
    "        \n",
    "        dclose=data.close.values\n",
    "        dopen=data.open.values\n",
    "        dhigh=data.high.values\n",
    "        dlow=data.low.values\n",
    "\n",
    "        for e in (range(len(data)-lookback)):\n",
    "\n",
    "            a=dclose[e:e+lookback]-dopen[e:e+lookback]\n",
    "            body=(a - np.min(a))/np.ptp(a)  \n",
    "\n",
    "            a=dhigh[e:e+lookback]-dlow[e:e+lookback]\n",
    "            range_=(a - np.min(a))/np.ptp(a)\n",
    "\n",
    "            diff_1=body-ptn_body\n",
    "            diff_2=range_-ptn_range\n",
    "            diff_1=np.where((diff_1<pct)&(diff_1>-pct),1,diff_1)\n",
    "            diff_1=np.where(diff_1!=1,0,diff_1)\n",
    "            diff_2=np.where((diff_2<pct)&(diff_2>-pct),1,diff_2)\n",
    "            diff_2=np.where(diff_2!=1,0,diff_2)\n",
    "            if (sum(diff_1)>=pct_total)&(sum(diff_2)>=pct_total):\n",
    "                data[\"signal\"][e+lookback]=True\n",
    "\n",
    "        return data[\"signal\"]    \n",
    "    \n",
    "    \n",
    "\n",
    "def old_sharpe_ratio(operations):\n",
    "    \"\"\"\n",
    "    Il rapporto tra il guadagno totale \n",
    "    e la deviazione standard dell'equity line\n",
    "    \"\"\"\n",
    "    if len(operations)>3:\n",
    "        equity = operations.cumsum()\n",
    "        netprofit = equity[-1]\n",
    "        std = equity.std()\n",
    "        if std != 0:\n",
    "            return round(netprofit / std,2)\n",
    "        else:\n",
    "            return np.inf\n",
    "    else:\n",
    "        return np.inf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
